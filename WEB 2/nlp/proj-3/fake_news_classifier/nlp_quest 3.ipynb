{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4af5236",
   "metadata": {},
   "source": [
    "# Introduction to NLP in Python\n",
    "## Quest 3: Creating your own fake news classifier\n",
    "\n",
    "The rise of social media and the proliferation of digital news sources have made it easier than ever to spread misinformation and fake news. As a result, this prompts the need to be able to distinguish between real and fake news stories. Machine learning techniques offer a promising solution to this, by allowing us to classify news articles based on their content and other features.\n",
    "\n",
    "In this quest, we explore the use of machine learning classification methods to classify news articles as either real or fake. We will analyse the text of the news articles based on the natural language processing (NLP) methods learnt in previous quests, and evaluate the performance of our classifier using a variety of metrics. \n",
    "\n",
    "**Do take note:** Lines that contain underscores are for you to fill in with your code! Do remove the underscores before running the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe4d3d",
   "metadata": {},
   "source": [
    "##### Part 1: Data Preprocessing using NLP Techniques\n",
    "\n",
    "In this first section, we will first perform some exploratory data analysis on the data provided, and preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2052f9c",
   "metadata": {},
   "source": [
    "1. Import the necesary libraries and methods. The libraries listed below are the basic data science libraries that you can use, but feel free to import other libraries that you feel will help you along this quest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf12dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab298ea5",
   "metadata": {},
   "source": [
    "2. Read the dataset from the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d8c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_news_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caffac5",
   "metadata": {},
   "source": [
    "3. After loading the dataset, perform some primary exploratory data analysis to understand the dataset provided. You can use simple pandas methods and attributes such as `head()`, `shape` and `info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ffa7b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploratory data analysis to familiarize yourself with the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2751c2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e57d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20242 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20761 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db0979e",
   "metadata": {},
   "source": [
    "4. Before proceeding, it is always a good measure to check if null values are present in the dataset or not. \n",
    "\n",
    "If there are null values in the DataFrame, use the `fillna` method to fill the null values with an empty string (i.e. \"\") Remember to specify the `axis=1` parameter to fill the missing values along the columns of the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa589935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values and if any, fill them with an empty string \n",
    "df.isnull().sum()\n",
    "df.fillna(\"\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f62f8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    House Dem Aide: We Didn’t Even See Comey’s Let...\n",
       "1    Ever get the feeling your life circles the rou...\n",
       "2    Why the Truth Might Get You Fired October 29, ...\n",
       "3    Videos 15 Civilians Killed In Single US Airstr...\n",
       "4    Print \\nAn Iranian woman has been sentenced to...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca23c16",
   "metadata": {},
   "source": [
    "5. For data preprocessing, we will focus on the 'text' column of the DataFrame, which contains the content of each news article. We will apply tokenization, the first text preprocessing method covered in Quest 1.\n",
    "\n",
    "Since the dataset has over 20,000 rows of data, it might take a while for the tokenization to finish running, depending on your machine specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e14b15c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word_tokenize(text)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Apply the tokenize_text function to the 'text' column of the DataFrame and create a new column 'tokenized_text'\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenized_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m, in \u001b[0;36mtokenize_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_text\u001b[39m(text):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py:107\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03mReturn a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03musing NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m:param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1281\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03m    Given a text, returns a list of the sentences in that text.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentences_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign_boundaries\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1341\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.sentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\n\u001b[0;32m   1333\u001b[0m     \u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1335\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[s:e] \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1341\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentences_from_text\u001b[39m(\n\u001b[0;32m   1333\u001b[0m     \u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1335\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;124;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;124;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;124;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;124;03m    follows the period.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[s:e] \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1329\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.span_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m realign_boundaries:\n\u001b[0;32m   1328\u001b[0m     slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_realign_boundaries(text, slices)\n\u001b[1;32m-> 1329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m slices:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (sentence\u001b[38;5;241m.\u001b[39mstart, sentence\u001b[38;5;241m.\u001b[39mstop)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1459\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;124;03mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m \u001b[38;5;124;03mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;124;03m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1458\u001b[0m realign \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence1, sentence2 \u001b[38;5;129;01min\u001b[39;00m _pair_iter(slices):\n\u001b[0;32m   1460\u001b[0m     sentence1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(sentence1\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m+\u001b[39m realign, sentence1\u001b[38;5;241m.\u001b[39mstop)\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sentence2:\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:321\u001b[0m, in \u001b[0;36m_pair_iter\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    319\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 321\u001b[0m     prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1431\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_slices_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mslice\u001b[39m]:\n\u001b[0;32m   1430\u001b[0m     last_break \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1431\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m match, context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_potential_end_contexts(text):\n\u001b[0;32m   1432\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_contains_sentbreak(context):\n\u001b[0;32m   1433\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(last_break, match\u001b[38;5;241m.\u001b[39mend())\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py:1395\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._match_potential_end_contexts\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1393\u001b[0m previous_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1394\u001b[0m previous_match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1395\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lang_vars\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperiod_context_re\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1396\u001b[0m \n\u001b[0;32m   1397\u001b[0m     \u001b[38;5;66;03m# Get the slice of the previous word\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m     before_text \u001b[38;5;241m=\u001b[39m text[previous_slice\u001b[38;5;241m.\u001b[39mstop : match\u001b[38;5;241m.\u001b[39mstart()]\n\u001b[0;32m   1399\u001b[0m     index_after_last_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_last_whitespace_index(before_text)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# Define a function to tokenize the text given\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Apply the tokenize_text function to the 'text' column of the DataFrame and create a new column 'tokenized_text'\n",
    "df['tokenized_text'] = tokenize_text(df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0fb96",
   "metadata": {},
   "source": [
    "6. With our new column containing the tokens of the text, we will dive into the second preprocessing step, which is to remove the stop words from the tokens.\n",
    "\n",
    "Create a list `stop_words` that contains the NLTK predefined stopwords. Recall that the stopwords module was imported in the first cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec139f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13f3e2",
   "metadata": {},
   "source": [
    "7. Define a function that removes stop words from a list of tokens. Take note that the NLTK predefined stopwords are in lowercase, while some of the tokens in your current DataFrame contain uppercase alphabets. \n",
    "\n",
    "Apply the method you have defined to the `tokenized_text` column. You can choose to create a new column for these tokens without stopwords, or replace the `tokenized_text` column entirely to only contain tokens without stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e06c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove stopwords from a list of tokens\n",
    "def remove_stopwords(tokens):\n",
    "    tokens_without_stopwords = [____ for ____ in ____ if ____.lower() not in ____]     # replace and fill in underscores\n",
    "    return tokens_without_stopwords\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tokenized_text' column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0083e9",
   "metadata": {},
   "source": [
    "##### Part 2: Separating the dataset and Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3fba8",
   "metadata": {},
   "source": [
    "8. Before we proceed, we will separate the dataset into features and targets. This allows us to clearly define the inputs and outputs of our model. \n",
    "\n",
    "The features are the independent variables that we use to predict the target variable, which is the dependent variable we want to predict. In this case, we are using the text from the article to determine if the article is reliable or unreliable. Reliable articles are labelled '0' in the `label` column while unreliable articles are labelled '1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928d91f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate the data into features and targets\n",
    "X_df = df['tokenized_text']\n",
    "y_df = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8270e470",
   "metadata": {},
   "source": [
    "9. Analyse the `y_df` data. Notice that the data type appears to be a `str` or `object` data type. \n",
    "\n",
    "Recall that we are looking to have a binary output which should only include numerical values. To train the model, we need to convert the label column into a numerical one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70162a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = y_df.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360c894",
   "metadata": {},
   "source": [
    "10. As machine learning models take in numerical values for their inputs, we have to convert our feature data into numerical format as well. This is where we can incorporate our vectorization skills covered in Quest 2!\n",
    "\n",
    "Import the `TfidfVectorizer` and create a TfidfVectorizer object. Since the features we are working with are in tokens, we have to specify this in the parameter as the vectorizer takes in strings by default. \n",
    "\n",
    "We set the `tokenizer` parameter to a lambda function that simply returns each document as-is. We also set `lowercase=False` to ensure that the tokenization is not modified.\n",
    "\n",
    "After this, fit and transform the vectorizer on the tokenized documents `x_df`. This produces the TFIDF matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform vectorization using the TFIDF Vectorizer and fit and transform the tokenized documents\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
    "tfidf = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1569c369",
   "metadata": {},
   "source": [
    "##### Part 3: Training and testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec5c74",
   "metadata": {},
   "source": [
    "11. Excellent! For the last part of this quest, we will be making use of a `LogisticRegression` model to create our fake news classifier. Logistic Regression has been covered in previous campaigns, but if you are new to this, don't worry as it is a relatively simple model to pick up. You can find out more about the different methods and attributes of Logistic Regression [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "We will split the data into a training set and a testing set to evaluate the performance of our Logistic Regression model. The training set is used to train the model, while the testing set is used to evaluate the model's performance on new data that is has not seen before. This helps us to determine how well the model will generalize to new data and avoid overfitting. \n",
    "\n",
    "This is important because the ultimate goal of a machine learning model is to make accurate predictions on new, real-world data. Without a testing set, we would have no way to evaluate the performance of our model on new data. \n",
    "\n",
    "Now with our TFIDF matrix and target data, we can split the data into testing and training sets using `train_test_split`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002fa916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(_____, _____, random_state=0)     # replace and fill in underscores     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac8fff",
   "metadata": {},
   "source": [
    "12. Import the necessary modules and create a LogisticRegression object. Fit the model according to the X and y training data produced above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8254cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = \n",
    "logreg.fit(_____, _____)     # replace and fill in underscores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87090ab2",
   "metadata": {},
   "source": [
    "13. Now that the model has been trained, obtain the predictions of the model using the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a75376",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2333ef",
   "metadata": {},
   "source": [
    "14. Now we need to evaluate how well the model did. Here, we use three evaluation metrics to assess the performance of our model. These are the metrics we will be working with:\n",
    "\n",
    "+ **Accuracy**: Accuracy is the proportion of correct predictions made by the model out of all the predictions made. It is calculated as the ratio of the number of correct predictions to the total number of predictions.\n",
    "+ **Precision**: Precision is the proportion of true positives out of all the positive predictions made by the model. It is calculated as the ratio of the number of true positives to the total number of positive predictions.\n",
    "+ **Recall**: Recall is the proportion of true positives out of all the actual positive cases in the dataset. It is calculated as the ratio of the number of true positives to the total number of actual positive cases.\n",
    "\n",
    "Import the following metrics and calculate the scores by comparing the test targets to the predicted targets of the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = \n",
    "recall = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ce86b",
   "metadata": {},
   "source": [
    "In machine learning, multiple metrics for evaluation is typically used as a single metric may not provide a complete picture of the model's performance. Different metrics capture different aspects of model performance, and evaluating a model using multiple metrics helps to provide a better understanding of how well the model is performing.\n",
    "\n",
    "For example, a model with high accuracy may have poor performance for a specific class, or may be overfitting the training data. In this case, we may need to look at other metrics, such as precision and recall, to better understand the model's performance. Similarly, a model with high precision may have low recall, indicating that it is good at identifying positive cases, but is missing some of the actual positive cases.\n",
    "\n",
    "By using multiple metrics for evaluation, we can identify the strengths and weaknesses of the model to make informed decisions about how to improve its performance. It is important to choose evaluation metrics that are relevant to the data you are dealing with, and consider the trade-offs between different metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25aaca2",
   "metadata": {},
   "source": [
    "15. Print out each of the scores for your model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy score is \", accuracy)\n",
    "print(\"The precision score is \", precision)\n",
    "print(\"The recall score is \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e38df",
   "metadata": {},
   "source": [
    "Congratulations! You have made it to the end of the quest! Now you have learnt to use your various NLP skills in machine learning projects.\n",
    "\n",
    "**Head back to the StackUp platform** to view the instructions for your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
